{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1\n",
        "\n",
        "У нас есть маленький корпус: * corpus = [\"Мама мыла раму\", \"Даша мыла яблоки\", \"Даша очень любит\n",
        "маму\"]\n",
        "Напишите код, с помощью которого вы получите такой результат: [\"мама мыть рама\", \"даша мыть яблоко\", \"даша очень любить мама\"]. Положите результат в переменную corpus_lem"
      ],
      "metadata": {
        "id": "XQUDQ61E_81a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попытки через Pymorphy и Mystem"
      ],
      "metadata": {
        "id": "TpWlSmekShb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "!pip install pymystem3==0.1.10\n",
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /root/.local/bin/mystem\n",
        "from pymystem3 import Mystem\n",
        "mystem = Mystem()"
      ],
      "metadata": {
        "id": "5X-XbNS0Thvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"Мама мыла раму\", \"Даша мыла яблоки\", \"Даша очень любит маму\"]"
      ],
      "metadata": {
        "id": "-7EFGOxMTirY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "from nltk import download\n",
        "download ('punkt')"
      ],
      "metadata": {
        "id": "NPMK4xT5Ti66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp=[]\n",
        "def lemmatize(a_text):\n",
        "    a_tokens = wordpunct_tokenize(a_text)\n",
        "    a_lemmatized = [morph.parse(item)[0].normal_form for item in a_tokens]\n",
        "    a_lemmatized = ' '.join([token for token in a_lemmatized if token.isalpha()])\n",
        "    print(a_lemmatized)\n",
        "    corp.append((a_lemmatized))\n",
        "    return a_lemmatized"
      ],
      "metadata": {
        "id": "1kiV7XKxTqKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for str in corpus:  lemmatize(str)"
      ],
      "metadata": {
        "id": "KoeKpqUfTqhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp"
      ],
      "metadata": {
        "id": "vd7uOB8XT-gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp[0]=corp[0].replace('мыло', 'мыть')\n",
        "corp[1]=corp[1].replace('мыло', 'мыть')"
      ],
      "metadata": {
        "id": "3dn5weQuUIV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp #вот здесь с заменой получилось!\n",
        "['мама мыть рама', 'даша мыть яблоко', 'даша очень любить мама']"
      ],
      "metadata": {
        "id": "TkZzJ-gLUDCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "И снова попытка выбрать Мыть"
      ],
      "metadata": {
        "id": "37aOVNeXUrxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.analyze('Даша мыла яблоко') # но дальше придумать не смогла"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxdgU2bYad6D",
        "outputId": "5c1659b7-2ade-480b-ee58-2bc128b357dd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'analysis': [{'lex': 'даша', 'wt': 1, 'gr': 'S,имя,жен,од=им,ед'}],\n",
              "  'text': 'Даша'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'мыло',\n",
              "    'wt': 0.5584790111,\n",
              "    'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}],\n",
              "  'text': 'мыла'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'яблоко', 'wt': 1, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}],\n",
              "  'text': 'яблоко'},\n",
              " {'text': '\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2\n",
        "\n",
        "Продолжаем. Дополните код ниже, чтобы получить словарь такого * вида: {'мама': 0, 'мыть': 1, 'рама': 2, 'даша': 3, 'яблоко': 4, 'очень': 5, 'любить': 6}\n",
        "corpus_tokenized = [sentence.split() for sentence in corpus_lem]\n",
        "words_indices = {}\n",
        "for sentence in corpus_tokenized:\n",
        "your code here"
      ],
      "metadata": {
        "id": "8e2bOdsRADON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "stops = stopwords.words(\"russian\")\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer=\"word\", # анализировать по словам или по символам (char)\n",
        "        stop_words=stops, # передаём список стоп-слов для русского из NLTK\n",
        "    ngram_range=(1, 1)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "739qeBN0tHVQ",
        "outputId": "61fbceba-1134-44f3-f29b-fb9528f28ad3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_lem = [\"мама мыть рама\", \"даша мыть яблоко\", \"даша очень любить мама\"]"
      ],
      "metadata": {
        "id": "zKwk74njl3Vd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "FnmN9ofIvJaQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = tfidf_vectorizer.fit_transform(corpus_lem)\n",
        "print(tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhLN1Uu1u7mh",
        "outputId": "9f344139-62fb-4e66-ad74-e36ab793091e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5)\t0.680918560398684\n",
            "  (0, 3)\t0.5178561161676974\n",
            "  (0, 2)\t0.5178561161676974\n",
            "  (1, 6)\t0.680918560398684\n",
            "  (1, 0)\t0.5178561161676974\n",
            "  (1, 3)\t0.5178561161676974\n",
            "  (2, 1)\t0.5628290964997665\n",
            "  (2, 4)\t0.5628290964997665\n",
            "  (2, 0)\t0.42804603506311856\n",
            "  (2, 2)\t0.42804603506311856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.vocabulary_\n",
        "print(tfidf_vectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "PconA1SNvYnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_lem"
      ],
      "metadata": {
        "id": "1yEzQvqstEHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tokenized = [sentence.split() for sentence in corpus_lem] \n",
        "corpus_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9sDcnS0uQd6",
        "outputId": "f4868489-7959-4033-b4a2-086f1b62b580"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['мама', 'мыть', 'рама'],\n",
              " ['даша', 'мыть', 'яблоко'],\n",
              " ['даша', 'очень', 'любить', 'мама']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = tfidf_vectorizer.fit_transform(corpus_lem)\n",
        "print(tfidf)\n",
        "\n",
        "tfidf.shape\n",
        "tfidf.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihcXcBYF4bV0",
        "outputId": "c03c0084-8c07-496c-c751-a6a2d181753a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5)\t0.680918560398684\n",
            "  (0, 3)\t0.5178561161676974\n",
            "  (0, 2)\t0.5178561161676974\n",
            "  (1, 6)\t0.680918560398684\n",
            "  (1, 0)\t0.5178561161676974\n",
            "  (1, 3)\t0.5178561161676974\n",
            "  (2, 1)\t0.5628290964997665\n",
            "  (2, 4)\t0.5628290964997665\n",
            "  (2, 0)\t0.42804603506311856\n",
            "  (2, 2)\t0.42804603506311856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.        , 0.        , 0.51785612, 0.51785612, 0.        ,\n",
              "         0.68091856, 0.        ],\n",
              "        [0.51785612, 0.        , 0.        , 0.51785612, 0.        ,\n",
              "         0.        , 0.68091856],\n",
              "        [0.42804604, 0.5628291 , 0.42804604, 0.        , 0.5628291 ,\n",
              "         0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNXb8UNV5rgb",
        "outputId": "230b71f5-6c1e-4ea5-a6e5-abf1aa3f3d85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'мама': 2,\n",
              " 'мыть': 3,\n",
              " 'рама': 5,\n",
              " 'даша': 0,\n",
              " 'яблоко': 6,\n",
              " 'очень': 4,\n",
              " 'любить': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tokenized = [sentence.split() for sentence in corpus_lem] #здесь так и не поняла, как мне перебрать слова\n",
        "words_indices = {}\n",
        "for sentence in corpus_tokenized:\n",
        "  words_indices[word] = len(words_indices)\n",
        "words_indices"
      ],
      "metadata": {
        "id": "GTHiacO58Br5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tokenized\n",
        "words_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmw_oXBy0FiS",
        "outputId": "f1c02aa7-173b-4c86-9467-7e0b0b8024ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поэтому сделала для строки\n"
      ],
      "metadata": {
        "id": "482GfqzC4tC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tokenized = 'мама мыть рама даша яблоко очень любить'.split()\n",
        "words_indices = {}\n",
        "for i in corpus_tokenized:\n",
        "  words_indices[i] = len(words_indices)\n",
        "words_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLziUE9t3yWt",
        "outputId": "47a66fa0-8473-4b45-db2d-d9c2806a5292"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'мама': 0,\n",
              " 'мыть': 1,\n",
              " 'рама': 2,\n",
              " 'даша': 3,\n",
              " 'яблоко': 4,\n",
              " 'очень': 5,\n",
              " 'любить': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_lem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cumJvPnY42qQ",
        "outputId": "3d263519-bec2-405c-b155-1098e61196d4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['мама мыть рама', 'даша мыть яблоко', 'даша очень любить мама']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 3\n",
        "\n",
        "Теперь посчитаем для каждого слова idf (inversed document frequency)."
      ],
      "metadata": {
        "id": "l3lG2R032SI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_indices = {'мама': 0, 'мыть': 1, 'рама': 2, 'даша': 3, 'яблоко': 4, 'очень': 5, 'любить': 6}"
      ],
      "metadata": {
        "id": "uGeOnsOJ2Nl5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = tfidf_vectorizer.get_feature_names_out()\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvh_LMHH4Hnf",
        "outputId": "04cb2dd9-fcb0-42f5-fe73-7345ad26c363"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['даша', 'любить', 'мама', 'мыть', 'очень', 'рама', 'яблоко'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = tfidf_vectorizer.get_feature_names_out()\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBFtLw5KwwlP",
        "outputId": "45493a22-a394-4b69-8e17-ae1e8eb604b7"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['даша', 'любить', 'мама', 'мыть', 'очень', 'рама', 'яблоко'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    }
  ]
}